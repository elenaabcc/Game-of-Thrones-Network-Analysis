---
title: "GOT GOT_G Analysis"
output: html_document
date: '2023-05-25'
---

# Network Structure:

The network is represented as an undirected graph, as indicated by the "Undirected" value in the "Type" column. The nodes in the network represent characters from the Game of Thrones series. The edges represent connections between characters. The weight of an edge indicates the strength or importance of the connection between the characters.

```{r}
library(igraph)
#etwd("~/Desktop/workspace/NETWORK ANALYSIS")
book1 <- read.csv("C:\\Users\\elena.martarello\\OneDrive - Safilo\\other\\Immagini\\book1.csv")
book2 <- read.csv("C:\\Users\\elena.martarello\\OneDrive - Safilo\\other\\Immagini\\book2.csv")
book3 <- read.csv("C:\\Users\\elena.martarello\\OneDrive - Safilo\\other\\Immagini\\book3.csv")
book4 <- read.csv("C:\\Users\\elena.martarello\\OneDrive - Safilo\\other\\Immagini\\book4.csv")
GOT  <- na.omit(rbind(book1, book2, book3, book4))

```

```{r}
unique_vertices <- unique(c(GOT$Source, GOT$Target))
GOT_G <- graph_from_data_frame(GOT, directed = FALSE)
GOT_1 = graph_from_data_frame(book1, directed = FALSE)
GOT_2 = graph_from_data_frame(book2, directed = FALSE)
GOT_3 = graph_from_data_frame(book3, directed = FALSE)
GOT_4 = graph_from_data_frame(book4, directed = FALSE)

#plot(GOT_G)
#print(GOT_G)
```

```{r}
# Create the nodes dataframe
nodes_df <- data.frame(ID = unique(c(GOT$Source, GOT$Target)), Label = unique(c(GOT$Source, GOT$Target)))

# Save the nodes dataframe as a tab-delimited text file
write.table(nodes_df, "nodes.txt", sep = "\t", quote = FALSE, row.names = FALSE)


```

```{r}
# Create the edges dataframe
edges_df <- GOT[, c("Source", "Target")]

# Save the edges dataframe as a tab-delimited text file
write.table(edges_df, "edges.txt", sep = "\t", quote = FALSE, row.names = FALSE)



```

To determine the three most important characters in the Game of Thrones network, you can consider different centrality measures. Two commonly used centrality measures are degree centrality and betweenness centrality.

Degree centrality measures the number of connections a character has in the network, indicating their popularity or influence. Higher degree centrality suggests greater importance.

Betweenness centrality measures the extent to which a character serves as a bridge or intermediary between other characters in the network. Higher betweenness centrality indicates a character's ability to control or influence information flow.

```{r}
# Calcola la distribuzione dei gradi
degree_dist <- degree_distribution(GOT_G)

# Converti la distribuzione dei gradi in un vettore
degree_vector <- as.vector(degree_dist)

# Disegna la distribuzione dei gradi a barre
barplot(degree_vector, main = "Degree Dist of GOT", xlab = "Degree", ylab = "Freuency")
```

# Top 3 character with the highest degree centrality\_ 1st book

```{r}
# Calculate degree centrality
degree_centrality_book_1 <- degree(GOT_1)

# Sort the degree centrality values in descending order
sorted_degree_book_1 <- sort(degree_centrality_book_1, decreasing = TRUE)

# Get the names of the three characters with the highest degree centrality
top_3_degree <- names(sorted_degree_book_1)[1:3]

# Print the results
cat("Top 3 characters by degree centrality in the first book:", top_3_degree, "\n")

```

# Top 3 character with the highest degree centrality: 2nd book

```{r}
# Calculate degree centrality
degree_centrality_book_2 <- degree(GOT_2)

# Sort the degree centrality values in descending order
sorted_degree_book_2 <- sort(degree_centrality_book_2, decreasing = TRUE)

# Get the names of the three characters with the highest degree centrality
top_3_degree <- names(sorted_degree_book_2)[1:3]

# Print the results
cat("Top 3 characters by degree centrality in the first book:", top_3_degree, "\n")

```

# Top 3 character with the highest degree centrality : 3th book

```{r}
# Calculate degree centrality
degree_centrality_book_3 <- degree(GOT_3)

# Sort the degree centrality values in descending order
sorted_degree_book_3 <- sort(degree_centrality_book_3, decreasing = TRUE)

# Get the names of the three characters with the highest degree centrality
top_3_degree <- names(sorted_degree_book_3)[1:3]

# Print the results
cat("Top 3 characters by degree centrality in the first book:", top_3_degree, "\n")

```

```{r}
# Calculate degree centrality
degree_centrality_book_4 <- degree(GOT_4)

# Sort the degree centrality values in descending order
sorted_degree_book_4 <- sort(degree_centrality_book_4, decreasing = TRUE)

# Get the names of the three characters with the highest degree centrality
top_3_degree <- names(sorted_degree_book_4)[1:3]

# Print the results
cat("Top 3 characters by degree centrality in the first book:", top_3_degree, "\n")

```

# Top 3 character with the highest degree centrality cross book

```{r}
# Calculate degree centrality
degree_centrality <- degree(GOT_G)

# Sort the degree centrality values in descending order
sorted_degree <- sort(degree_centrality, decreasing = TRUE)

# Get the names of the three characters with the highest degree centrality
top_3_degree <- names(sorted_degree)[1:3]

# Print the results
cat("Top 3 characters by degree centrality:", top_3_degree, "\n")

```

## Their evolution on the 4 books

```{r}
# Lista dei personaggi di interesse
characters <- c("Tyrion-Lannister", "Cersei-Lannister", "Jaime-Lannister")

# Creazione di un data frame vuoto per i risultati
degree_df <- data.frame(Book = 1:length(unique(GOT$book)),
                        Tyrion_Lannister = numeric(length(unique(GOT$book))),
                        Cersei_Lannister = numeric(length(unique(GOT$book))),
                        Jaime_Lannister = numeric(length(unique(GOT$book))))

# Calcolo della degree centrality per ogni libro e personaggio
for (i in 1:length(unique(GOT$book))) {
  book <- subgraph.edges(GOT_G, which(E(GOT_G)$book == i))
  degree_values <- degree(book, v = characters)
  degree_df[i, c("Tyrion_Lannister", "Cersei_Lannister", "Jaime_Lannister")] <- degree_values
}

# Visualizzazione del data frame dei risultati
#print(degree_df)

library(ggplot2)

# Plotting the degree centrality evolution
ggplot(degree_df, aes(x = Book)) +
  geom_line(aes(y = Tyrion_Lannister, color = "Tyrion Lannister")) +
  geom_line(aes(y = Cersei_Lannister, color = "Cersei Lannister")) +
  geom_line(aes(y = Jaime_Lannister, color = "Jaime Lannister")) +
  labs(x = "Book", y = "Degree Centrality", color = "Character") +
  scale_color_manual(values = c("Tyrion Lannister" = "red", "Cersei Lannister" = "blue", "Jaime Lannister" = "green")) +
  theme_minimal()

```

# Top 3 character with the highest betweenness centrality

```{r}
# Calculate betweenness centrality
betweenness_centrality<- betweenness(GOT_G)

# Normalize the betweenness centrality values
normalized_betweenness <- (betweenness_centrality - min(betweenness_centrality)) / (max(betweenness_centrality) - min(betweenness_centrality))

# Sort the normalized betweenness centrality values in descending order
sorted_normalized_betweenness <- sort(normalized_betweenness, decreasing = TRUE)

# Get the names of the three characters with the highest normalized betweenness centrality
top_3_normalized_betweenness <- names(sorted_normalized_betweenness)[1:3]

# Print the results
cat("Top 3 characters by normalized betweenness centrality:", top_3_normalized_betweenness, "\n")

```

# BC in the 1st book

```{r}
# Calculate betweenness centrality
betweenness_centrality_1<- betweenness(GOT_1)

# Normalize the betweenness centrality values
normalized_betweenness <- (betweenness_centrality_1 - min(betweenness_centrality_1)) / (max(betweenness_centrality_1) - min(betweenness_centrality_1))

# Sort the normalized betweenness centrality values in descending order
sorted_normalized_betweenness <- sort(normalized_betweenness, decreasing = TRUE)

# Get the names of the three characters with the highest normalized betweenness centrality
top_3_normalized_betweenness <- names(sorted_normalized_betweenness)[1:3]

# Print the results
cat("Top 3 characters by normalized betweenness centrality:", top_3_normalized_betweenness, "\n")
```

# BC in the 2nd book

```{r}
# Calculate betweenness centrality
betweenness_centrality_2<- betweenness(GOT_2)

# Normalize the betweenness centrality values
normalized_betweenness <- (betweenness_centrality_2 - min(betweenness_centrality_2)) / (max(betweenness_centrality_2) - min(betweenness_centrality_2))

# Sort the normalized betweenness centrality values in descending order
sorted_normalized_betweenness <- sort(normalized_betweenness, decreasing = TRUE)

# Get the names of the three characters with the highest normalized betweenness centrality
top_3_normalized_betweenness <- names(sorted_normalized_betweenness)[1:3]

# Print the results
cat("Top 3 characters by normalized betweenness centrality:", top_3_normalized_betweenness, "\n")

```

# BC in the 3th book

```{r}
# Calculate betweenness centrality
betweenness_centrality_3 <- betweenness(GOT_3)

# Normalize the betweenness centrality values
normalized_betweenness <- (betweenness_centrality_3 - min(betweenness_centrality_3)) / (max(betweenness_centrality_3) - min(betweenness_centrality_3))

# Sort the normalized betweenness centrality values in descending order
sorted_normalized_betweenness <- sort(normalized_betweenness, decreasing = TRUE)

# Get the names of the three characters with the highest normalized betweenness centrality
top_3_normalized_betweenness <- names(sorted_normalized_betweenness)[1:3]

# Print the results
cat("Top 3 characters by normalized betweenness centrality:", top_3_normalized_betweenness, "\n")


```

# BC in the 4th book

```{r}
# Calculate betweenness centrality
betweenness_centrality_4 <- betweenness(GOT_4)

# Normalize the betweenness centrality values
normalized_betweenness <- (betweenness_centrality_4 - min(betweenness_centrality_4)) / (max(betweenness_centrality_4) - min(betweenness_centrality_4))

# Sort the normalized betweenness centrality values in descending order
sorted_normalized_betweenness <- sort(normalized_betweenness, decreasing = TRUE)

# Get the names of the three characters with the highest normalized betweenness centrality
top_3_normalized_betweenness <- names(sorted_normalized_betweenness)[1:3]

# Print the results
cat("Top 3 characters by normalized betweenness centrality:", top_3_normalized_betweenness, "\n")

```

## Their evolution on the 4 books

```{r}
# Lista dei personaggi di interesse
characters <- c("Jaime-Lannister", "Jon-Snow", "Robert-Baratheon")

# Creazione di un data frame vuoto per i risultati
betweenness_df <- data.frame(Book = 1:length(unique(GOT$book)),
                             Jaime_Lannister = numeric(length(unique(GOT$book))),
                             Jon_Snow = numeric(length(unique(GOT$book))),
                             Robert_Baratheon = numeric(length(unique(GOT$book))))

# Calcolo della betweenness centrality per ogni libro e personaggio
for (i in 1:length(unique(GOT$book))) {
  book <- subgraph.edges(GOT_G, which(E(GOT_G)$book == i))
  betweenness_values <- betweenness(book, v = characters)
  betweenness_df[i, c("Jaime_Lannister", "Jon_Snow", "Robert_Baratheon")] <- betweenness_values
}

# Visualizzazione del data frame dei risultati
#print(betweenness_df)

library(ggplot2)

# Plotting the betweenness centrality evolution
ggplot(betweenness_df, aes(x = Book)) +
  geom_line(aes(y = Jaime_Lannister, color = "Jaime Lannister")) +
  geom_line(aes(y = Jon_Snow, color = "Jon Snow")) +
  geom_line(aes(y = Robert_Baratheon, color = "Robert Baratheon")) +
  labs(x = "Book", y = "Betweenness Centrality", color = "Character") +
  scale_color_manual(values = c("Jaime Lannister" = "red", "Jon Snow" = "blue", "Robert Baratheon" = "green")) +
  theme_minimal()

```

# Coomunity Detection

```{r}

# Apply community detection using the Louvain algorithm
communities <- cluster_louvain(GOT_G)


# Get the membership (community assignment) of each vertex
membership <- membership(communities)

# Get the number of communities
num_communities <- length(communities)

# Iterate over each community
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_G)$name[which(membership(communities) == i)]
  
  # Print the community ID and its composition
  cat("Community", i, ": ", vertices_in_community, "\n")
}
```

Modularity Analysis: Modularity measures the strength of division of a network into communities. You can calculate the modularity score for the detected communities in your network. Higher modularity scores indicate stronger community structure.

```{r}
modularity <- modularity(communities)

# Print the modularity score
print(modularity)

```

Network Visualization: Visualizing the network with nodes colored according to their community membership can provide an intuitive understanding of the community structure. Tools like Gephi, Cytoscape, or igraph's plotting functions in R can help you visualize and explore the network communities.

```{r}
node_colors <- rainbow(max(membership(communities)))

# Plot the network with colored nodes
#plot(GOT_G, vertex.color = node_colors)
```

#Community Metrics:

Compute various community-level metrics to gain insights into their properties. Some common metrics include community size (number of nodes), average node degree, density, centralities (e.g., betweenness centrality), etc. These metrics can help you understand the internal structure and importance of communities within the network.

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_G)$name[which(membership == i)]
  
  # Calculate the average degree for the current community
  avg_degree <- mean(degree(GOT_G, vertices_in_community))
  
  # Print the community ID, its composition, and average degree
  cat("Community", i,"Average Degree:",": ", avg_degree, "\n\n")
}
```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_G)$name[which(membership == i)]
  
  # Calculate the density for the current community
  subgraph <- induced_subgraph(GOT_G, vertices_in_community)
  num_edges <- ecount(subgraph)
  num_vertices <- vcount(subgraph)
  community_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Print the community ID, its composition, and density
  cat("Community", i, "Density:", community_density, "\n\n")
}


```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_G)$name[which(membership == i)]
  
  # Calculate the number of nodes for the current community
  num_nodes <- length(vertices_in_community)
  
  # Print the community ID, its composition, and number of nodes
  cat("Community", i, "Number of Nodes:", num_nodes, "\n\n")
}

```

```{r}
# Calculate the community centralities
community_centralities <- list()

for (i in 1:num_communities) {
  subgraph <- induced_subgraph(GOT_G, V(GOT_G)$name[which(membership == i)])

  degree_centrality <- degree(subgraph)
  betweenness_centrality <- betweenness(subgraph)
  closeness_centrality <- closeness(subgraph)

  centralities <- data.frame(
    degree = degree_centrality,
    betweenness = betweenness_centrality,
    closeness = closeness_centrality
  )

  community_centralities[[i]] <- centralities
}

# Print the community centralities
for (i in 1:num_communities) {
  cat("Community", i, "Centralities:\n")
  cat("Degree:", community_centralities[[i]]$degree, "\n")
  cat("Betweenness:", community_centralities[[i]]$betweenness, "\n")
  cat("Closeness:", community_centralities[[i]]$closeness, "\n")
  cat("\n")
}

```

# Community Comparison:

Compare different community detection algorithms or parameter settings to evaluate their effectiveness in identifying communities. You can assess the overlap, similarity, or differences between communities detected by different methods.

Overlap: 13. This indicates that there are 13 vertices that are assigned to communities by both the Louvain algorithm and the Walktrap algorithm. These vertices are part of the communities identified by both methods.

Similarity: 0.1477273 (approximately 0.15). This represents the ratio of overlapping vertices to the total number of unique vertices assigned by both methods. In this case, about 15% of the vertices assigned by the algorithms are part of the communities identified by both methods.

Difference: 639. This indicates the number of vertices that are assigned to different communities by the Louvain algorithm and the Walktrap algorithm. These vertices have different community assignments depending on the method used.

These results suggest that there is some level of agreement (overlap and similarity) between the communities detected by the two algorithms, but there are also notable differences (difference) in their community assignments. Further analysis and consideration may be required to understand the reasons for these differences and assess the effectiveness of each algorithm or parameter setting in identifying communities in your network.

```{r}

# Apply community detection using different algorithms or parameter settings
communities_louvain <- cluster_louvain(GOT_G)$membership
communities_walktrap <- cluster_walktrap(GOT_G)$membership

# Compare the communities detected by different methods
overlap <- length(intersect(communities_louvain, communities_walktrap))
similarity <- length(intersect(communities_louvain, communities_walktrap)) / length(union(communities_louvain, communities_walktrap))
difference <- sum(communities_louvain != communities_walktrap)

# Print the comparison results
cat("Overlap:", overlap, "\n")
cat("Similarity:", similarity, "\n")
cat("Difference:", difference, "\n")
```

# topological ground truths,

```{r}
#degree centrality of nodes within the community
  degree_centrality <- degree(GOT_G, community_nodes)
  
  # Example: Calculate the clustering coefficient for each node within the community
  clustering_coefficient <- sapply(community_nodes, function(node) {
    neighborhood <- neighbors(GOT_G, node)
    subgraph <- induced_subgraph(GOT_G, c(node, neighborhood))
    transitivity(subgraph, type = "local")
  })
  
  # Calculate the average path length of nodes within the community
  average_path_length <- sapply(community_nodes, function(node) {
    distances <- distances(GOT_G, v = node)
    sum(distances) / (length(distances) - 1)
  })
  
  # Return a data frame with the functional attributes of nodes within the community
  data.frame(
    Node = V(GOT_G)$name[community_nodes],
    DegreeCentrality = degree_centrality,
    ClusteringCoefficient = clustering_coefficient,
    AveragePathLength = average_path_length)
  })

# Print the functional attributes of nodes within each community
for (i in seq_along(community_ids)) {
  current_community <- community_ids[i]
  current_community_functionality <- community_functionality[[i]]
  
  cat("Community", current_community, "\n")
  print(current_community_functionality)
  cat("\n")
}


```

# community book 1

```{r}

# Apply community detection using the Louvain algorithm
communities_1 <- cluster_louvain(GOT_1)


# Get the membership (community assignment) of each vertex
membership <- membership(communities_1)

# Get the number of communities
num_communities <- length(communities_1)

# Iterate over each community
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_1)$name[which(membership(communities_1) == i)]
  
  # Print the community ID and its composition
  cat("Community", i, ": ", vertices_in_community, "\n")
}
```

Modularity Analysis: Modularity measures the strength of division of a network into communities. You can calculate the modularity score for the detected communities in your network. Higher modularity scores indicate stronger community structure.

```{r}
modularity <- modularity(communities_1)

# Print the modularity score
print(modularity)

```

#Community Metrics:

Compute various community-level metrics to gain insights into their properties. Some common metrics include community size (number of nodes), average node degree, density, centralities (e.g., betweenness centrality), etc. These metrics can help you understand the internal structure and importance of communities within the network.

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_1)$name[which(membership == i)]
  
  # Calculate the average degree for the current community
  avg_degree <- mean(degree(GOT_1, vertices_in_community))
  
  # Print the community ID, its composition, and average degree
  cat("Community", i,"Average Degree:",": ", avg_degree, "\n\n")
}
```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_1)$name[which(membership == i)]
  
  # Calculate the density for the current community
  subgraph <- induced_subgraph(GOT_1, vertices_in_community)
  num_edges <- ecount(subgraph)
  num_vertices <- vcount(subgraph)
  community_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Print the community ID, its composition, and density
  cat("Community", i, "Density:", community_density, "\n\n")
}


```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_1)$name[which(membership == i)]
  
  # Calculate the number of nodes for the current community
  num_nodes <- length(vertices_in_community)
  
  # Print the community ID, its composition, and number of nodes
  cat("Community", i, "Number of Nodes:", num_nodes, "\n\n")
}

```

# Community Comparison:

Compare different community detection algorithms or parameter settings to evaluate their effectiveness in identifying communities. You can assess the overlap, similarity, or differences between communities detected by different methods.

Overlap: 13. This indicates that there are 13 vertices that are assigned to communities by both the Louvain algorithm and the Walktrap algorithm. These vertices are part of the communities identified by both methods.

Similarity: 0.1477273 (approximately 0.15). This represents the ratio of overlapping vertices to the total number of unique vertices assigned by both methods. In this case, about 15% of the vertices assigned by the algorithms are part of the communities identified by both methods.

Difference: 639. This indicates the number of vertices that are assigned to different communities by the Louvain algorithm and the Walktrap algorithm. These vertices have different community assignments depending on the method used.

These results suggest that there is some level of agreement (overlap and similarity) between the communities detected by the two algorithms, but there are also notable differences (difference) in their community assignments. Further analysis and consideration may be required to understand the reasons for these differences and assess the effectiveness of each algorithm or parameter setting in identifying communities in your network.

```{r}

# Apply community detection using different algorithms or parameter settings
communities_louvain <- cluster_louvain(GOT_1)$membership
communities_walktrap <- cluster_walktrap(GOT_1)$membership

# Compare the communities detected by different methods
overlap <- length(intersect(communities_louvain, communities_walktrap))
similarity <- length(intersect(communities_louvain, communities_walktrap)) / length(union(communities_louvain, communities_walktrap))
difference <- sum(communities_louvain != communities_walktrap)

# Print the comparison results
cat("Overlap:", overlap, "\n")
cat("Similarity:", similarity, "\n")
cat("Difference:", difference, "\n")

```

# community book 2

```{r}

# Apply community detection using the Louvain algorithm
communities_2 <- cluster_louvain(GOT_2)


# Get the membership (community assignment) of each vertex
membership <- membership(communities_2)

# Get the number of communities
num_communities <- length(communities_2)

# Iterate over each community
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_2)$name[which(membership(communities_2) == i)]
  
  # Print the community ID and its composition
  cat("Community", i, ": ", vertices_in_community, "\n")
}
```

Modularity Analysis: Modularity measures the strength of division of a network into communities. You can calculate the modularity score for the detected communities in your network. Higher modularity scores indicate stronger community structure.

```{r}
modularity <- modularity(communities_2)

# Print the modularity score
print(modularity)

```

#Community Metrics:

Compute various community-level metrics to gain insights into their properties. Some common metrics include community size (number of nodes), average node degree, density, centralities (e.g., betweenness centrality), etc. These metrics can help you understand the internal structure and importance of communities within the network.

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_2)$name[which(membership == i)]
  
  # Calculate the average degree for the current community
  avg_degree <- mean(degree(GOT_2, vertices_in_community))
  
  # Print the community ID, its composition, and average degree
  cat("Community", i,"Average Degree:",": ", avg_degree, "\n\n")
}
```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_2)$name[which(membership == i)]
  
  # Calculate the density for the current community
  subgraph <- induced_subgraph(GOT_2, vertices_in_community)
  num_edges <- ecount(subgraph)
  num_vertices <- vcount(subgraph)
  community_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Print the community ID, its composition, and density
  cat("Community", i, "Density:", community_density, "\n\n")
}


```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_2)$name[which(membership == i)]
  
  # Calculate the number of nodes for the current community
  num_nodes <- length(vertices_in_community)
  
  # Print the community ID, its composition, and number of nodes
  cat("Community", i, "Number of Nodes:", num_nodes, "\n\n")
}

```

# Community Comparison:

Compare different community detection algorithms or parameter settings to evaluate their effectiveness in identifying communities. You can assess the overlap, similarity, or differences between communities detected by different methods.

Overlap: 13. This indicates that there are 13 vertices that are assigned to communities by both the Louvain algorithm and the Walktrap algorithm. These vertices are part of the communities identified by both methods.

Similarity: 0.1477273 (approximately 0.15). This represents the ratio of overlapping vertices to the total number of unique vertices assigned by both methods. In this case, about 15% of the vertices assigned by the algorithms are part of the communities identified by both methods.

Difference: 639. This indicates the number of vertices that are assigned to different communities by the Louvain algorithm and the Walktrap algorithm. These vertices have different community assignments depending on the method used.

These results suggest that there is some level of agreement (overlap and similarity) between the communities detected by the two algorithms, but there are also notable differences (difference) in their community assignments. Further analysis and consideration may be required to understand the reasons for these differences and assess the effectiveness of each algorithm or parameter setting in identifying communities in your network.

```{r}

# Apply community detection using different algorithms or parameter settings
communities_louvain <- cluster_louvain(GOT_2)$membership
communities_walktrap <- cluster_walktrap(GOT_2)$membership

# Compare the communities detected by different methods
overlap <- length(intersect(communities_louvain, communities_walktrap))
similarity <- length(intersect(communities_louvain, communities_walktrap)) / length(union(communities_louvain, communities_walktrap))
difference <- sum(communities_louvain != communities_walktrap)

# Print the comparison results
cat("Overlap:", overlap, "\n")
cat("Similarity:", similarity, "\n")
cat("Difference:", difference, "\n")
```


# community book 3

```{r}

# Apply community detection using the Louvain algorithm
communities_3 <- cluster_louvain(GOT_3)


# Get the membership (community assignment) of each vertex
membership <- membership(communities_3)

# Get the number of communities
num_communities <- length(communities_3)

# Iterate over each community
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_3)$name[which(membership(communities_3) == i)]
  
  # Print the community ID and its composition
  cat("Community", i, ": ", vertices_in_community, "\n")
}
```

Modularity Analysis: Modularity measures the strength of division of a network into communities. You can calculate the modularity score for the detected communities in your network. Higher modularity scores indicate stronger community structure.

```{r}
modularity <- modularity(communities_3)

# Print the modularity score
print(modularity)

```

#Community Metrics:

Compute various community-level metrics to gain insights into their properties. Some common metrics include community size (number of nodes), average node degree, density, centralities (e.g., betweenness centrality), etc. These metrics can help you understand the internal structure and importance of communities within the network.

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_3)$name[which(membership == i)]
  
  # Calculate the average degree for the current community
  avg_degree <- mean(degree(GOT_3, vertices_in_community))
  
  # Print the community ID, its composition, and average degree
  cat("Community", i,"Average Degree:",": ", avg_degree, "\n\n")
}
```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_3)$name[which(membership == i)]
  
  # Calculate the density for the current community
  subgraph <- induced_subgraph(GOT_3, vertices_in_community)
  num_edges <- ecount(subgraph)
  num_vertices <- vcount(subgraph)
  community_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Print the community ID, its composition, and density
  cat("Community", i, "Density:", community_density, "\n\n")
}


```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_3)$name[which(membership == i)]
  
  # Calculate the number of nodes for the current community
  num_nodes <- length(vertices_in_community)
  
  # Print the community ID, its composition, and number of nodes
  cat("Community", i, "Number of Nodes:", num_nodes, "\n\n")
}

```

# Community Comparison:

Compare different community detection algorithms or parameter settings to evaluate their effectiveness in identifying communities. You can assess the overlap, similarity, or differences between communities detected by different methods.

Overlap: 13. This indicates that there are 13 vertices that are assigned to communities by both the Louvain algorithm and the Walktrap algorithm. These vertices are part of the communities identified by both methods.

Similarity: 0.1477273 (approximately 0.15). This represents the ratio of overlapping vertices to the total number of unique vertices assigned by both methods. In this case, about 15% of the vertices assigned by the algorithms are part of the communities identified by both methods.

Difference: 639. This indicates the number of vertices that are assigned to different communities by the Louvain algorithm and the Walktrap algorithm. These vertices have different community assignments depending on the method used.

These results suggest that there is some level of agreement (overlap and similarity) between the communities detected by the two algorithms, but there are also notable differences (difference) in their community assignments. Further analysis and consideration may be required to understand the reasons for these differences and assess the effectiveness of each algorithm or parameter setting in identifying communities in your network.

```{r}

# Apply community detection using different algorithms or parameter settings
communities_louvain <- cluster_louvain(GOT_3)$membership
communities_walktrap <- cluster_walktrap(GOT_3)$membership

# Compare the communities detected by different methods
overlap <- length(intersect(communities_louvain, communities_walktrap))
similarity <- length(intersect(communities_louvain, communities_walktrap)) / length(union(communities_louvain, communities_walktrap))
difference <- sum(communities_louvain != communities_walktrap)

# Print the comparison results
cat("Overlap:", overlap, "\n")
cat("Similarity:", similarity, "\n")
cat("Difference:", difference, "\n")
```


# community book 4

```{r}

# Apply community detection using the Louvain algorithm
communities_4 <- cluster_louvain(GOT_4)


# Get the membership (community assignment) of each vertex
membership <- membership(communities_4)

# Get the number of communities
num_communities <- length(communities_4)

# Iterate over each community
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_4)$name[which(membership(communities_4) == i)]
  
  # Print the community ID and its composition
  cat("Community", i, ": ", vertices_in_community, "\n")
}
```

Modularity Analysis: Modularity measures the strength of division of a network into communities. You can calculate the modularity score for the detected communities in your network. Higher modularity scores indicate stronger community structure.

```{r}
modularity <- modularity(communities_4)

# Print the modularity score
print(modularity)

```

#Community Metrics:

Compute various community-level metrics to gain insights into their properties. Some common metrics include community size (number of nodes), average node degree, density, centralities (e.g., betweenness centrality), etc. These metrics can help you understand the internal structure and importance of communities within the network.

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_4)$name[which(membership == i)]
  
  # Calculate the average degree for the current community
  avg_degree <- mean(degree(GOT_4, vertices_in_community))
  
  # Print the community ID, its composition, and average degree
  cat("Community", i,"Average Degree:",": ", avg_degree, "\n\n")
}
```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_4)$name[which(membership == i)]
  
  # Calculate the density for the current community
  subgraph <- induced_subgraph(GOT_4, vertices_in_community)
  num_edges <- ecount(subgraph)
  num_vertices <- vcount(subgraph)
  community_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Print the community ID, its composition, and density
  cat("Community", i, "Density:", community_density, "\n\n")
}


```

```{r}
for (i in 1:num_communities) {
  # Get the vertices within the current community
  vertices_in_community <- V(GOT_4)$name[which(membership == i)]
  
  # Calculate the number of nodes for the current community
  num_nodes <- length(vertices_in_community)
  
  # Print the community ID, its composition, and number of nodes
  cat("Community", i, "Number of Nodes:", num_nodes, "\n\n")
}

```

# Community Comparison:

Compare different community detection algorithms or parameter settings to evaluate their effectiveness in identifying communities. You can assess the overlap, similarity, or differences between communities detected by different methods.

Overlap: 13. This indicates that there are 13 vertices that are assigned to communities by both the Louvain algorithm and the Walktrap algorithm. These vertices are part of the communities identified by both methods.

Similarity: 0.1477273 (approximately 0.15). This represents the ratio of overlapping vertices to the total number of unique vertices assigned by both methods. In this case, about 15% of the vertices assigned by the algorithms are part of the communities identified by both methods.

Difference: 639. This indicates the number of vertices that are assigned to different communities by the Louvain algorithm and the Walktrap algorithm. These vertices have different community assignments depending on the method used.

These results suggest that there is some level of agreement (overlap and similarity) between the communities detected by the two algorithms, but there are also notable differences (difference) in their community assignments. Further analysis and consideration may be required to understand the reasons for these differences and assess the effectiveness of each algorithm or parameter setting in identifying communities in your network.

```{r}

# Apply community detection using different algorithms or parameter settings
communities_louvain <- cluster_louvain(GOT_3)$membership
communities_walktrap <- cluster_walktrap(GOT_3)$membership

# Compare the communities detected by different methods
overlap <- length(intersect(communities_louvain, communities_walktrap))
similarity <- length(intersect(communities_louvain, communities_walktrap)) / length(union(communities_louvain, communities_walktrap))
difference <- sum(communities_louvain != communities_walktrap)

# Print the comparison results
cat("Overlap:", overlap, "\n")
cat("Similarity:", similarity, "\n")
cat("Difference:", difference, "\n")
```

